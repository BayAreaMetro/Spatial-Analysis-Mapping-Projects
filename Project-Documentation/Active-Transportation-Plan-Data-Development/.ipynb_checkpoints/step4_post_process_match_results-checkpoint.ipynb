{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c730c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob, getpass\n",
    "import pandas as pd\n",
    "import fiona\n",
    "import geopandas as gpd\n",
    "\n",
    "username = getpass.getuser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb42914",
   "metadata": {},
   "source": [
    "## Set up input/output folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "797ee09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "geojson_dir = os.path.join('/Users',\n",
    "                          username,\n",
    "                          'Box',\n",
    "                          'Dataviz Projects',\n",
    "                          'Spatial Analysis and Mapping',\n",
    "                          'Active Transportation Plan',\n",
    "                          'Data',\n",
    "                          'geojson')\n",
    "match_dir = os.path.join('/Users',\n",
    "                        username,\n",
    "                        'Box',\n",
    "                        'DataViz Projects',\n",
    "                        'Spatial Analysis and Mapping',\n",
    "                        'Active Transportation Plan',\n",
    "                        'Data',\n",
    "                        'shst_match_results',\n",
    "                        'matched')\n",
    "output_dir = os.path.join('/Users',\n",
    "                          username,\n",
    "                          'Box',\n",
    "                          'MTC Data for Toole Design',\n",
    "                          'final_nw_datasets')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d06e7c8",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14da6fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_list = [\n",
    "    'san_jose_bike_nw_epsg4326',\n",
    "    'vta_bike_network_v2_epsg4326',\n",
    "    'batc_bike_network_v2_epsg4326',\n",
    "    'caltrans_d4_bike_network_epsg4326',\n",
    "    'oakland_bike_network_epsg4326',\n",
    "    'batc_bike_network_epsg4326',\n",
    "    'vta_bike_network_epsg4326',\n",
    "    'tam_bike_network_epsg4326',\n",
    "    'sta_bike_network_epsg4326',\n",
    "    'sfcta_bike_network_epsg4326',\n",
    "    'scta_bike_network_epsg4326',\n",
    "    'nvta_bike_network_epsg4326',\n",
    "    'ccta_bike_network_epsg4326',\n",
    "   'ccag_bike_network_epsg4326',\n",
    "    'actc_bike_network_epsg4326'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c4871c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_file = 'actc_bike_network_epsg4326'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "0cf3dde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_deduplicate_matched_nw(match_dir,in_file):\n",
    "    \"\"\"\n",
    "    Merge and deduplicate matched exising and proposed bike network datasets. \n",
    "    \n",
    "    Return dataframe. \n",
    "    \"\"\"\n",
    "    \n",
    "    match_files = glob.glob(match_dir + '/' + in_file + '?*.geojson')\n",
    "    \n",
    "    col_name_dict = {\n",
    "        'san_jose_bike_nw_epsg4326': 'sj',\n",
    "        'vta_bike_network_v2_epsg4326': 'cma',\n",
    "        'batc_bike_network_v2_epsg4326': 'batc',\n",
    "        'caltrans_d4_bike_network_epsg4326': 'caltrans',\n",
    "        'oakland_bike_network_epsg4326': 'oak',\n",
    "        'tam_bike_network_epsg4326': 'cma',\n",
    "        'sta_bike_network_epsg4326': 'cma',\n",
    "        'sfcta_bike_network_epsg4326': 'cma',\n",
    "        'scta_bike_network_epsg4326': 'cma',\n",
    "        'nvta_bike_network_epsg4326': 'cma',\n",
    "        'ccta_bike_network_epsg4326': 'cma',\n",
    "        'ccag_bike_network_epsg4326': 'cma',\n",
    "        'actc_bike_network_epsg4326': 'cma'\n",
    "    }\n",
    "    \n",
    "    print('----------Start reading shst match results data-------------')\n",
    "    \n",
    "    concat_gdf = gpd.GeoDataFrame()\n",
    "    for file in match_files:\n",
    "        print('Reading shst match results data: ' + file)\n",
    "        gdf = gpd.read_file(file)\n",
    "        concat_gdf = pd.concat([concat_gdf,gdf],\n",
    "                               ignore_index=True,\n",
    "                               sort=False)\n",
    "        \n",
    "    print('----------Finished reading shst match results data----------')\n",
    "    \n",
    "    print('\\n-----------Renaming columns-------------------------------')\n",
    "    \n",
    "    rename_dict = {\n",
    "        'pp_ex_class':col_name_dict[in_file] + '_ex_class',\n",
    "        'pp_pln_class':col_name_dict[in_file] + '_pln_class',\n",
    "        'source':col_name_dict[in_file] + '_source',\n",
    "        'pp_mtc_facility_id':'mtc_facility_id'\n",
    "    }\n",
    "    \n",
    "    concat_gdf.rename(columns=rename_dict,\n",
    "                      inplace=True)\n",
    "\n",
    "    print('\\n-----------Reprojecting-----------------------------------')\n",
    "    \n",
    "    concat_gdf.to_crs('EPSG:3857',inplace=True)\n",
    "    \n",
    "    print('\\n-----------Adding link length column----------------------')\n",
    "    \n",
    "    concat_gdf['length'] = concat_gdf['geometry'].length\n",
    "    \n",
    "    print('\\n--Sorting by length decending, drop duplicates by subset--')\n",
    "    print('\\nCount of records: ',concat_gdf.shape[0])\n",
    "    \n",
    "    subset = [\n",
    "        'shstReferenceId',\n",
    "        'shstGeometryId'\n",
    "    ]\n",
    "    dedup_gdf = (\n",
    "        concat_gdf\n",
    "        .sort_values('length',ascending=False)\n",
    "        .drop_duplicates(subset=subset,keep='first')\n",
    "        .copy()\n",
    "    )\n",
    "    \n",
    "    print('\\nFinal count of deduped records: ',dedup_gdf.shape[0])\n",
    "    \n",
    "    col_subset = [\n",
    "        'shstReferenceId',\n",
    "        'shstGeometryId',\n",
    "        'fromIntersectionId',\n",
    "        'toIntersectionId',\n",
    "        col_name_dict[in_file] + '_ex_class',\n",
    "        col_name_dict[in_file] + '_pln_class',\n",
    "        col_name_dict[in_file] + '_source',\n",
    "        'mtc_facility_id'\n",
    "    ]\n",
    "    return dedup_gdf[col_subset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "1c3896ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Start reading shst match results data-------------\n",
      "Reading shst match results data: /Users/jcroff/Box/DataViz Projects/Spatial Analysis and Mapping/Active Transportation Plan/Data/shst_match_results/matched/actc_bike_network_epsg4326_exst_matched.geojson\n",
      "Reading shst match results data: /Users/jcroff/Box/DataViz Projects/Spatial Analysis and Mapping/Active Transportation Plan/Data/shst_match_results/matched/actc_bike_network_epsg4326_ppsd_matched.geojson\n",
      "----------Finished reading shst match results data----------\n",
      "\n",
      "-----------------Renaming columns-------------------------\n",
      "\n",
      "----------------Reprojecting------------------------------\n",
      "\n",
      "-----------Adding link length column----------------------\n",
      "\n",
      "--Sorting by length decending, drop duplicates by subset--\n",
      "\n",
      "Count of records:  89550\n",
      "\n",
      "Final count of deduped records:  45519\n"
     ]
    }
   ],
   "source": [
    "actc_dedup = merge_deduplicate_matched_nw(match_dir=match_dir,in_file=in_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "b12b4aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_matched_raw_nw(matched_df,geojson_dir,in_file):\n",
    "    \"\"\"\n",
    "    Compare matched bike network to original raw input and return unmatched as gdf.\n",
    "    \"\"\"\n",
    "    print('-----------Reading raw files------------------------------')\n",
    "    \n",
    "    raw_file = os.path.join(geojson_dir,in_file +'.geojson')\n",
    "    \n",
    "    raw_gdf = gpd.read_file(raw_file)\n",
    "    \n",
    "    raw_cols = raw_gdf.columns.to_list()\n",
    "    \n",
    "    print('\\n-----------Merging matched and raw files------------------')\n",
    "    \n",
    "    raw_match_merge = pd.merge(raw_gdf,\n",
    "                           actc_dedup,\n",
    "                           how='left',\n",
    "                           on='mtc_facility_id',\n",
    "                           indicator=True)\n",
    "    \n",
    "    print('\\n----------Creating new unmatched dataframe----------------')\n",
    "    \n",
    "    unmatched_gdf = raw_match_merge[raw_match_merge['_merge'] == 'left_only'].copy()\n",
    "    \n",
    "    print('\\nUnmatched records: ',unmatched.shape[0])\n",
    "    \n",
    "    return unmatched_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "3ff4e4d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------Reading raw files------------------------------\n",
      "\n",
      "-----------Merging matched and raw files------------------\n",
      "\n",
      "----------Creating new unmatched dataframe----------------\n",
      "\n",
      "Unmatched records:  6542\n"
     ]
    }
   ],
   "source": [
    "actc_unmatched = compare_matched_raw_nw(matched_df=actc_dedup,geojson_dir=geojson_dir,in_file=in_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2033664c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
