{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import getpass\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely import wkt\n",
    "from mtcpy.geospatial import geom_to_hexwkb\n",
    "from mtcpy.aws import post_df_to_s3, create_redshift_table_via_s3, list_s3_buckets\n",
    "from mtcpy.analytics import create_column_type_dict\n",
    "\n",
    "user = getpass.getuser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "work_dir = pathlib.Path(\n",
    "    f\"/Users/{user}/Library/CloudStorage/Box-Box/DataViz Projects/Data Services/FasTrak Data\"\n",
    ")\n",
    "gc_data = work_dir / \"Fastrak Accounts Cleaned\" / \"bay_area_fastrak_accounts_geocoded.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def publish_df_s3_redshift(data_name, df, bucket=bucket, schema=\"accounts\"):\n",
    "    \"\"\"Given a DataFrame, or a GeoDataFrame, and Data Name, Push to S3\n",
    "    then publish to Redshift\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    # get column types\n",
    "    ctypes = create_column_type_dict(df)\n",
    "    # convert geometry to well-known binary (wkb) format\n",
    "    if \"geometry\" in ctypes.keys():\n",
    "        if not df.crs == 4326:\n",
    "            df = df.to_crs(4326)\n",
    "        df[\"geometry\"] = df[\"geometry\"].apply(lambda x: geom_to_hexwkb(x) if x != None else None)\n",
    "        ctypes[\"geometry\"] = \"geometry\"\n",
    "\n",
    "    ## Push to S3\n",
    "    key = f\"{schema}/{data_name}.csv\"\n",
    "    post_df_to_s3(df, bucket, key)\n",
    "\n",
    "    ## Push to Redshift\n",
    "    tablename = f\"{schema}.{data_name}\"\n",
    "    s3_path = f\"s3://{bucket}/{key}\"\n",
    "    create_redshift_table_via_s3(\n",
    "        tablename=tablename, s3_path=s3_path, ctypes=ctypes, dbname=\"fastrak_ds\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in gc_data and convert geometry with wkt to geodataframe\n",
    "df = pd.read_csv(gc_data)\n",
    "df['geometry'] = df['geometry'].apply(wkt.loads)\n",
    "# Convert the DataFrame to a GeoDataFrame\n",
    "gdf = gpd.GeoDataFrame(df, geometry='geometry', crs='EPSG:4326')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jcroff/anaconda3/envs/esri_env/lib/python3.11/site-packages/pandas/core/frame.py:4123: UserWarning: Geometry column does not contain geometry.\n",
      "  self[k1] = value[k2]\n",
      "/var/folders/9q/xt2lctm54xq6fd45m1lmgp4m0000gp/T/ipykernel_98055/2774522463.py:12: UserWarning: Geometry column does not contain geometry.\n",
      "  df[\"geometry\"] = df[\"geometry\"].apply(lambda x: geom_to_hexwkb(x) if x != None else None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Info: Set AWS creds using 'default' creds.\n",
      "dataframe on S3 at eps-upload:accounts/fastrak_addresses_geocoded.csv\n",
      "DROP TABLE IF EXISTS accounts.fastrak_addresses_geocoded\n",
      "\n",
      "\n",
      "CREATE TABLE accounts.fastrak_addresses_geocoded(\n",
      "address_orig varchar(136),\n",
      "formatted_address varchar(228),\n",
      "geometry_location_type varchar(36),\n",
      "types varchar(162),\n",
      "partial_match varchar(8),\n",
      "geometry geometry);\n",
      "\n",
      "\n",
      "COPY accounts.fastrak_addresses_geocoded\n",
      "                FROM 's3://eps-upload/accounts/fastrak_addresses_geocoded.csv'\n",
      "                CREDENTIALS 'aws_access_key_id=XXX;aws_secret_access_key=XXX'\n",
      "                EMPTYASNULL\n",
      "                FILLRECORD\n",
      "                TIMEFORMAT as auto\n",
      "                DATEFORMAT as auto\n",
      "                NULL AS nan\n",
      "                CSV\n",
      "                IGNOREHEADER 1;\n",
      "\n",
      "\n",
      "table created on Redshift: accounts.fastrak_addresses_geocoded\n"
     ]
    }
   ],
   "source": [
    "bucket = \"eps-upload\"\n",
    "publish_df_s3_redshift(\n",
    "    data_name=\"fastrak_addresses_geocoded\", df=gdf, bucket=bucket, schema=\"accounts\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "esri_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
