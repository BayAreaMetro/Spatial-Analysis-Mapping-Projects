---
title: "Communities of Concern 2018"
output: html_notebook
---

This script builds the 2016 Community of Concern Dataset using the prescribed methodology located here:   [GitHub Documentation](https://github.com/BayAreaMetro/Spatial-Analysis-Mapping-Projects/tree/master/Project-Documentation/Communities-of-Concern). 

It uses the censusapi library which is documented here: [CensusAPI](https://hrecht.github.io/censusapi/index.html)

```{r message=FALSE, warning=FALSE}
library(censusapi)
library(readr)
library(dplyr)
#Community of Concern Spatial Processing
library(censusapi)
library(readr)
library(dplyr)
### Install Mapping Libraries
# install.packages("leaflet")
# install.packages("rgdal")
# install.packages("geojsonio")
# install.packages("spdplyr")
# install.packages("rmapshaper")
# install.packages("jsonlite")
#install.packages("knitr")
#library(leaflet)
library(jsonlite)
library(rgdal)
#library(geojsonio)
library(spdplyr)
library(rmapshaper)
library(knitr)
library(tidyr)

setwd("~/Documents/Github_Documentation/Spatial-Analysis-Mapping-Projects/Project-Documentation/Communities-of-Concern/Data")
#This key is private and should not be shared via GitHub.  It is here for internal use only.  This portion of the code should be removed when sharing to Github.
Sys.getenv("CENSUS_TOKEN")
# Add key to .Renviron
Sys.setenv(CENSUS_KEY='CENSUS_KEY')
# Reload .Renviron
readRenviron("~/.Renviron")
# Check to see that the expected key is output in your R console
Sys.getenv("CENSUS_KEY")
#Provides list of APIs 
apis <- listCensusApis()
```

```{r message=FALSE, warning=FALSE}
ACS_COC_SelectedVars <- read_csv("~/Documents/Github_Documentation/Spatial-Analysis-Mapping-Projects/Project-Documentation/Communities-of-Concern/Data/ACS_Table_Variables_COC_Factors.csv")
acs_vars <- ACS_COC_SelectedVars$ACS_Table_Variable
#rm(selectedData)
selectedData <- getCensus(name="acs/acs5", vintage=2016,
                          vars=acs_vars, 
                          region="tract:*", 
                          regionin="state:06+county:001,013,041,055,075,081,085,095,097")
head(selectedData)
```

#### Calculate COC variables from selectedData

```{r message=FALSE, warning=FALSE}
selectedData$GEOID <- paste(selectedData$state,selectedData$county,selectedData$tract,sep="")
selectedData$STATE <- selectedData$state
selectedData$COUNTY_FIPS <- selectedData$county
selectedData$TRACT <- selectedData$tract
selectedData$TOT_POP_MIN <- selectedData$B03002_001E 
selectedData$TOT_POP_SEN <- selectedData$B01001_001E
selectedData$TOT_POP_POV <- selectedData$C17002_001E
selectedData$TOT_POP_CIV_NI <- selectedData$C18108_001E
selectedData$TOT_HH <- selectedData$B08201_001E
selectedData$TOT_FAM <- selectedData$B11004_001E
selectedData$TOT_POP_OVER5 <- selectedData$B16005_001E
selectedData$POP_MINORITY <- selectedData$B03002_001E - selectedData$B03002_003E
selectedData$POP_OVER75 <- selectedData$B01001_023E + selectedData$B01001_024E + selectedData$B01001_025E + selectedData$B01001_047E + selectedData$B01001_048E + selectedData$B01001_049E
selectedData$POP_SPFAM <- selectedData$B11004_010E + selectedData$B11004_016E
selectedData$POP_LEP<- selectedData$B16005_007E + selectedData$B16005_008E + selectedData$B16005_012E + selectedData$B16005_013E + selectedData$B16005_017E + selectedData$B16005_018E + selectedData$B16005_022E + selectedData$B16005_023E + selectedData$B16005_029E + selectedData$B16005_030E + selectedData$B16005_034E + selectedData$B16005_035E + selectedData$B16005_039E + selectedData$B16005_040E + selectedData$B16005_044E + selectedData$B16005_045E
selectedData$POP_BELOW200 <- selectedData$C17002_001E - selectedData$C17002_008E
selectedData$POP_DISABILITY <- selectedData$C18108_001E - (selectedData$C18108_005E + selectedData$C18108_009E + selectedData$C18108_013E)
selectedData$POP_HUS_RENT50 <- selectedData$B25070_010E
selectedData$POP_ZVHHS <- selectedData$B08201_002E
selectedData$PCT_OVER75 <- ifelse(selectedData$B01001_001E == 0,0,((selectedData$B01001_023E + selectedData$B01001_024E + selectedData$B01001_025E + selectedData$B01001_047E + selectedData$B01001_048E + selectedData$B01001_049E)/selectedData$B01001_001E))
selectedData$PCT_MINORITY <- ifelse(selectedData$B03002_001E == 0,0,((selectedData$B03002_001E - selectedData$B03002_003E)/selectedData$B03002_001E))
selectedData$PCT_SPFAM <- ifelse(selectedData$B11004_001E == 0,0,((selectedData$B11004_010E + selectedData$B11004_016E)/selectedData$B11004_001E))
selectedData$PCT_LEP <- ifelse(selectedData$B16005_001E == 0,0,((selectedData$B16005_007E + selectedData$B16005_008E + selectedData$B16005_012E + selectedData$B16005_013E + selectedData$B16005_017E + selectedData$B16005_018E + selectedData$B16005_022E + selectedData$B16005_023E + selectedData$B16005_029E + selectedData$B16005_030E + selectedData$B16005_034E + selectedData$B16005_035E + selectedData$B16005_039E + selectedData$B16005_040E + selectedData$B16005_044E + selectedData$B16005_045E)/selectedData$B16005_001E))
selectedData$PCT_BELOW200 <- ifelse(selectedData$C17002_001E == 0,0,((selectedData$C17002_001E - selectedData$C17002_008E)/selectedData$C17002_001E))
selectedData$PCT_DISAB <- ifelse(selectedData$C18108_001E == 0,0,((selectedData$C18108_001E - (selectedData$C18108_005E + selectedData$C18108_009E + selectedData$C18108_013E))/selectedData$C18108_001E))
selectedData$PCT_ZVHHS <- ifelse(selectedData$B08201_001E == 0,0,(selectedData$B08201_002E/selectedData$B08201_001E))
selectedData$PCT_HUS_RENT50 <- ifelse(selectedData$B08201_001E == 0,0,(selectedData$B25070_010E/selectedData$B08201_001E))

head(selectedData)
```

#### Find Mean and St. Dev of Shares
For all shares, find the mean and standard deviation of the shares.

```{r}
# Build df with select fields
EJ_2018 <- selectedData[,c(1:3,42:68)]
ej_Shares <- EJ_2018[,c(1:7,23:30)]

a <- ej_Shares %>%
  summarise(FACTOR = 'Seniors', 
            REGIONAL_MEAN = mean(PCT_OVER75,na.rm = T),
            SD = sd(PCT_OVER75,na.rm = T), 
            PLUS_HALFSD = mean(PCT_OVER75,na.rm = T) + (sd(PCT_OVER75,na.rm = TRUE)/2), 
            PLUS_ONEHALFSD = mean(PCT_OVER75,na.rm = T) + sd(PCT_OVER75,na.rm = T), 
            PLUS_ONEHALFSD = mean(PCT_OVER75,na.rm = T) + (1.5 * sd(PCT_OVER75,na.rm = TRUE) ))

b <- ej_Shares %>%
  summarise(FACTOR = 'Minorities', 
            REGIONAL_MEAN = mean(PCT_MINORITY,na.rm = T),
            SD = sd(PCT_MINORITY,na.rm = T), 
            PLUS_HALFSD = mean(PCT_MINORITY,na.rm = T) + (sd(PCT_MINORITY,na.rm = TRUE)/2), 
            PLUS_ONEHALFSD = mean(PCT_MINORITY,na.rm = T) + sd(PCT_MINORITY,na.rm = T), 
            PLUS_ONEHALFSD = mean(PCT_MINORITY,na.rm = T) + (1.5 * sd(PCT_MINORITY,na.rm = TRUE) ))

c <- ej_Shares %>%
  summarise(FACTOR = 'Limited English Proficiency', 
            REGIONAL_MEAN = mean(PCT_LEP,na.rm = T),
            SD = sd(PCT_LEP,na.rm = T), 
            PLUS_HALFSD = mean(PCT_LEP,na.rm = T) + (sd(PCT_LEP,na.rm = TRUE)/2), 
            PLUS_ONEHALFSD = mean(PCT_LEP,na.rm = T) + sd(PCT_LEP,na.rm = T), 
            PLUS_ONEHALFSD = mean(PCT_LEP,na.rm = T) + (1.5 * sd(PCT_LEP,na.rm = TRUE) ))

d <- ej_Shares %>%
  summarise(FACTOR = 'Single Parent Families', 
            REGIONAL_MEAN = mean(PCT_SPFAM,na.rm = T),
            SD = sd(PCT_SPFAM,na.rm = T), 
            PLUS_HALFSD = mean(PCT_SPFAM,na.rm = T) + (sd(PCT_SPFAM,na.rm = TRUE)/2), 
            PLUS_ONEHALFSD = mean(PCT_SPFAM,na.rm = T) + sd(PCT_SPFAM,na.rm = T), 
            PLUS_ONEHALFSD = mean(PCT_SPFAM,na.rm = T) + (1.5 * sd(PCT_SPFAM,na.rm = TRUE) ))

e <- ej_Shares %>%
  summarise(FACTOR = 'Share of Population Below 200% FPL', 
            REGIONAL_MEAN = mean(PCT_BELOW200,na.rm = T),
            SD = sd(PCT_BELOW200,na.rm = T), 
            PLUS_HALFSD = mean(PCT_BELOW200,na.rm = T) + (sd(PCT_BELOW200,na.rm = TRUE)/2), 
            PLUS_ONEHALFSD = mean(PCT_BELOW200,na.rm = T) + sd(PCT_BELOW200,na.rm = T), 
            PLUS_ONEHALFSD = mean(PCT_BELOW200,na.rm = T) + (1.5 * sd(PCT_BELOW200,na.rm = TRUE) ))

f <- ej_Shares %>%
  summarise(FACTOR = 'Share of Disabled Population', 
            REGIONAL_MEAN = mean(PCT_DISAB,na.rm = T),
            SD = sd(PCT_DISAB,na.rm = T), 
            PLUS_HALFSD = mean(PCT_DISAB,na.rm = T) + (sd(PCT_DISAB,na.rm = TRUE)/2), 
            PLUS_ONEHALFSD = mean(PCT_DISAB,na.rm = T) + sd(PCT_DISAB,na.rm = T), 
            PLUS_ONEHALFSD = mean(PCT_DISAB,na.rm = T) + (1.5 * sd(PCT_DISAB,na.rm = TRUE) ))

g <- ej_Shares %>%
  summarise(FACTOR = 'Zero Vehicle Households', 
            REGIONAL_MEAN = mean(PCT_ZVHHS,na.rm = T),
            SD = sd(PCT_ZVHHS,na.rm = T), 
            PLUS_HALFSD = mean(PCT_ZVHHS,na.rm = T) + (sd(PCT_ZVHHS,na.rm = TRUE)/2), 
            PLUS_ONEHALFSD = mean(PCT_ZVHHS,na.rm = T) + sd(PCT_ZVHHS,na.rm = T), 
            PLUS_ONEHALFSD = mean(PCT_ZVHHS,na.rm = T) + (1.5 * sd(PCT_ZVHHS,na.rm = TRUE) ))

h <- ej_Shares %>%
  summarise(FACTOR = 'HUS Rent 50', 
            REGIONAL_MEAN = mean(PCT_HUS_RENT50,na.rm = T),
            SD = sd(PCT_HUS_RENT50,na.rm = T), 
            PLUS_HALFSD = mean(PCT_HUS_RENT50,na.rm = T) + (sd(PCT_HUS_RENT50,na.rm = TRUE)/2), 
            PLUS_ONEHALFSD = mean(PCT_HUS_RENT50,na.rm = T) + sd(PCT_HUS_RENT50,na.rm = T), 
            PLUS_ONEHALFSD = mean(PCT_HUS_RENT50,na.rm = T) + (1.5 * sd(PCT_HUS_RENT50,na.rm = TRUE) ))

region <- rbind(a,b,c,d,e,f,g,h)
rm(a,b,c,d,e,f,g,h)
write.csv(region,"~/Documents/Github_Documentation/Spatial-Analysis-Mapping-Projects/Project-Documentation/Communities-of-Concern/Data/COC_Regional_Stats.csv")
#write.csv(region,"/home/shared/Projects/Communities of Concern/data/COC_Regional_Stats.csv")
```

#### Logic flagging Disadvantage Factors
```{r}

#Flag factors within .5 Standard Deviation from mean of Regional Shares
selectedData$OVER75_HALFSD <- ifelse(selectedData$PCT_OVER75 > .10,1,0)
selectedData$MINORITY_HALFSD <- ifelse(selectedData$PCT_MINORITY > .70,1,0)
selectedData$SPFAM_HALFSD <- ifelse(selectedData$PCT_SPFAM > .20,1,0)
selectedData$DISAB_HALFSD <- ifelse(selectedData$PCT_DISAB > .12,1,0)
selectedData$LEP_HALFSD <- ifelse(selectedData$PCT_LEP > .12,1,0)
selectedData$BELOW200_HALFSD <- ifelse(selectedData$PCT_BELOW200 > .30,1,0)
selectedData$ZVHH_HALFSD <- ifelse(selectedData$PCT_ZVHHS > .10,1,0)
selectedData$HUS_RENT50_HALFSD <- ifelse(selectedData$PCT_HUS_RENT50 > .15,1,0)

selectedData$Count_DisadFact_HALFSD <- selectedData$OVER75_HALFSD + selectedData$SPFAM_HALFSD + selectedData$DISAB_HALFSD + selectedData$LEP_HALFSD + selectedData$ZVHH_HALFSD + selectedData$HUS_RENT50_HALFSD 

selectedData$COC_FLAG_2018 <- ifelse((selectedData$MINORITY_HALFSD == 1 & selectedData$BELOW200_HALFSD == 1) | (selectedData$BELOW200_HALFSD == 1 & selectedData$Count_DisadFact_HALFSD >= 3),1,0)

selectedData$COC_CLASS <- 'NA'

#Flag factors within 1 Standard Deviation from mean of Regional Shares

selectedData$OVER75_ONESD <- ifelse(selectedData$PCT_OVER75 > .11 & selectedData$PCT_OVER75 <= .13,1,0)
selectedData$MINORITY_ONESD <- ifelse(selectedData$PCT_MINORITY > .81 & selectedData$PCT_MINORITY <= .93,1,0)
selectedData$SPFAM_ONESD <- ifelse(selectedData$PCT_SPFAM > .23 & selectedData$PCT_SPFAM <= .27,1,0)
selectedData$DISAB_ONESD <- ifelse(selectedData$PCT_DISAB > .14 & selectedData$PCT_DISAB <= .16,1,0)
selectedData$LEP_ONESD <- ifelse(selectedData$PCT_LEP > .16 & selectedData$PCT_LEP <= .20,1,0)
selectedData$BELOW200_ONESD <- ifelse(selectedData$PCT_BELOW200 > .40 & selectedData$PCT_BELOW200 <= .48,1,0)
selectedData$ZVHH_ONESD <- ifelse(selectedData$PCT_ZVHHS > .22 & selectedData$PCT_ZVHHS <= .28,1,0)
selectedData$HUS_RENT50_ONESD <- ifelse(selectedData$PCT_HUS_RENT50 > .19 & selectedData$PCT_HUS_RENT50 <= .23,1,0)

selectedData$Count_DisadFact_ONESD <- selectedData$OVER75_ONESD + selectedData$SPFAM_ONESD + selectedData$DISAB_ONESD + selectedData$LEP_ONESD + selectedData$ZVHH_ONESD + selectedData$HUS_RENT50_ONESD 

selectedData$COC_FLAG_2018_ONESD <- ifelse((selectedData$MINORITY_ONESD == 1 & selectedData$BELOW200_ONESD == 1) | (selectedData$BELOW200_ONESD == 1 & selectedData$Count_DisadFact_ONESD >= 3),1,0)

#FLag factors within 1.5 Standard Deviation from mean of Regional Shares

selectedData$OVER75_ONEHALFSD <- ifelse(selectedData$PCT_OVER75 > .13,1,0)
selectedData$MINORITY_ONEHALFSD <- ifelse(selectedData$PCT_MINORITY > .93,1,0)
selectedData$SPFAM_ONEHALFSD <- ifelse(selectedData$PCT_SPFAM > .27,1,0)
selectedData$DISAB_ONEHALFSD <- ifelse(selectedData$PCT_DISAB > .16,1,0)
selectedData$LEP_ONEHALFSD <- ifelse(selectedData$PCT_LEP > .20,1,0)
selectedData$BELOW200_ONEHALFSD <- ifelse(selectedData$PCT_BELOW200 > .48,1,0)
selectedData$ZVHH_ONEHALFSD <- ifelse(selectedData$PCT_ZVHHS > .28,1,0)
selectedData$HUS_RENT50_ONEHALFSD <- ifelse(selectedData$PCT_HUS_RENT50 > .23,1,0)

selectedData$Count_DisadFact_ONEHALFSD <- selectedData$OVER75_ONEHALFSD + selectedData$SPFAM_ONEHALFSD + selectedData$DISAB_ONEHALFSD + selectedData$LEP_ONEHALFSD + selectedData$ZVHH_ONEHALFSD + selectedData$HUS_RENT50_ONEHALFSD 

selectedData$COC_FLAG_2018_ONEHALFSD <- ifelse((selectedData$MINORITY_ONEHALFSD == 1 & selectedData$BELOW200_ONEHALFSD == 1) | (selectedData$BELOW200_ONEHALFSD == 1 & selectedData$Count_DisadFact_ONEHALFSD >= 3),1,0)


selectedData <- selectedData %>%
  mutate(COC_CLASS = ifelse(COC_FLAG_2018_ONEHALFSD == 1, 'Highest',
                            ifelse(COC_FLAG_2018_ONESD == 1, 'Higher',
                                   ifelse(COC_FLAG_2018 == 1, 'High','NA'))))
selectedData$COC_CLASS <- as.factor(selectedData$COC_CLASS)
```

#### Export Final Table to CSV 
```{r}
FinalTable <- selectedData[,c(42:79)]


write.csv(FinalTable, "~/Documents/Github_Documentation/Spatial-Analysis-Mapping-Projects/Project-Documentation/Communities-of-Concern/Data/COCs_ACS2016_tbl.csv")
```

#### Read ACS 2014 COCs into DF and select subset containing GEOID and COC Flag. Perform same subset selection from Final Table
```{r}
COC_2014_ALL_DATA <- read.csv(file="~/Documents/Github_Documentation/Spatial-Analysis-Mapping-Projects/Project-Documentation/Communities-of-Concern/Data/COCS_ACS2014_tbl.csv", header=TRUE, sep=",")

COC_2014_SUBSET <- COC_2014_ALL_DATA[,c("GEOID","COCFLAG_2017")]

COC_2014_SUBSET$GEOID <- paste("0",COC_2014_SUBSET$GEOID,sep = "")

COC_2016_SUBSET <- FinalTable[,c("GEOID","COC_FLAG_2018")]
```
#### Compare 2017 COCs and 2018 COCs and output comparison CSV
```{r}
COC_COMPARE <- merge(COC_2014_SUBSET, COC_2016_SUBSET, by= "GEOID")

COC_COMPARE$Gain_Loss_2014_2016 <- COC_COMPARE$COC_FLAG_2018 - COC_COMPARE$COCFLAG_2017

write.csv(COC_COMPARE,"~/Documents/Github_Documentation/Spatial-Analysis-Mapping-Projects/Project-Documentation/Communities-of-Concern/Data/COC_Diff_ACS2014_ACS2016.csv")
```
