{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Info: Found credentials at: /Users/jcroff/Library/CloudStorage/Box-Box/dvutils-creds-jcroff.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd, geopandas as gp, numpy as np\n",
    "import getpass\n",
    "from arcgis import GIS\n",
    "\n",
    "user = getpass.getuser()\n",
    "\n",
    "DVUTILS_LOCAL_CLONE_PATH = f\"/Users/{user}/Documents/GitHub/dvutils\"\n",
    "sys.path.insert(0, DVUTILS_LOCAL_CLONE_PATH)\n",
    "from utils_io import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get census api key\n",
    "api_key = os.environ.get(\"CENSUS_API_KEY\")\n",
    "agol_password = os.environ.get(\"AGOL_CONTENT_PASSWORD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# authenticate to agol\n",
    "gis = GIS(url=\"https://mtc.maps.arcgis.com/home\", username=\"content_MTC\", password=agol_password)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read census api key from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_contents(filename):\n",
    "    \"\"\"Given a filename,\n",
    "    return the contents of that file\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(filename, \"r\") as f:\n",
    "            # It's assumed our file contains a single line,\n",
    "            # with our API key\n",
    "            return f.read().strip()\n",
    "    except FileNotFoundError:\n",
    "        print(\"'%s' file not found\" % filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flag_condition_calc(row, df_share_column, standard_deviation):\n",
    "    cond = (\n",
    "        df_share_column.mean().round(decimals=2)\n",
    "        + (standard_deviation * df_share_column.std().round(decimals=2))\n",
    "    ).round(decimals=2)\n",
    "    if row > cond:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flag_mult_columns(dataframe, dictionary, standard_deviation):\n",
    "    for key, value in dictionary.items():\n",
    "        dataframe[value] = dataframe[key].apply(\n",
    "            lambda row: flag_condition_calc(row, dataframe[key], standard_deviation)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_epc_class(df):\n",
    "    if df[\"epc50p_1ha\"] == 1:\n",
    "        return \"Highest\"\n",
    "    elif df[\"epc50p_1\"] == 1:\n",
    "        return \"Higher\"\n",
    "    elif df[\"epc50p_1_2\"] == 1:\n",
    "        return \"High\"\n",
    "    else:\n",
    "        return \"NA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flag_condition_calc(row, df_share_column, standard_deviation):\n",
    "    cond = (\n",
    "        df_share_column.mean().round(decimals=2)\n",
    "        + (standard_deviation * df_share_column.std().round(decimals=2))\n",
    "    ).round(decimals=2)\n",
    "    if row > cond:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pull_acs_5_year_est_data(\n",
    "    census_api_key,\n",
    "    acs_year=2019,\n",
    "    tbl_prof_type=\"Detailed\",\n",
    "    table_id=None,\n",
    "    select_table_vars=None,\n",
    "    drop_anno_cols=True,\n",
    "    drop_margin_cols=True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Pull American Community Survey (ACS) 5 year estimate data. Data can be pulled for an entire\n",
    "    table or for select table variables.\n",
    "\n",
    "    !Must include a table_id or list to select_table_vars parameters!\n",
    "\n",
    "    Parameters\n",
    "    -------------------\n",
    "    census_api_key (String):\n",
    "    Your secret census api key.\n",
    "\n",
    "    acs_year (Integer):\n",
    "    Year for acs estimates, default is 2019 which is latest year 5 year data is available.\n",
    "\n",
    "    tbl_prof_type (String):\n",
    "    Table or profile type. These include the following types: Detailed, Subject, Data, or Comparison.\n",
    "\n",
    "    table_id (String):\n",
    "    ACS table id. Example 'B01001'\n",
    "\n",
    "    select_table_vars (List):\n",
    "    provide a list of ACS table variables as strings. Example: ['B01001_001E','B01001_002E']\n",
    "\n",
    "    drop_anno_cols (Boolean):\n",
    "    Used if table_id provided. Drops annotation of margin of error and annotation of estimate\n",
    "    columns.\n",
    "\n",
    "    drop_margin_cols (Boolean):\n",
    "    Used if table_id provided. Drops margin of error columns.\n",
    "\n",
    "    Returns\n",
    "    -------------------\n",
    "    Geodataframe object\n",
    "\n",
    "    Author: Joshua Croff\n",
    "    Variable Reference: https://www.census.gov/data/developers/data-sets/acs-5year.html\n",
    "    \"\"\"\n",
    "    import requests\n",
    "    import pandas as pd\n",
    "\n",
    "    if table_id:\n",
    "        var = f\"group({table_id})\"\n",
    "    else:\n",
    "        var = \",\".join(select_table_vars)\n",
    "\n",
    "    counties = \"001,013,041,055,075,081,085,095,097\"\n",
    "    state = \"06\"\n",
    "    # set base url\n",
    "    if tbl_prof_type not in [\"Detailed\", \"Subject\", \"Data\", \"Comparison\"]:\n",
    "        return \"Please provide the following table types: Detailed, Subject, Data, or Comparison\"\n",
    "    elif tbl_prof_type == \"Detailed\":\n",
    "        base_url = f\"https://api.census.gov/data/{acs_year}/acs/acs5?\"\n",
    "    elif tbl_prof_type == \"Subject\":\n",
    "        base_url = f\"https://api.census.gov/data/{acs_year}/acs/acs5/subject?\"\n",
    "        # https://api.census.gov/data/2020/acs/acs5/subject?get=NAME,S0101_C01_001E&for=county:037&in=state:06&key=YOUR_KEY_GOES_HERE\n",
    "    elif tbl_prof_type == \"Data\":\n",
    "        base_url = f\"https://api.census.gov/data/{acs_year}/acs/acs5/profile?\"\n",
    "    else:\n",
    "        base_url = f\"https://api.census.gov/data/{acs_year}/acs/acs5/cprofile?\"\n",
    "\n",
    "    # set query params\n",
    "    query_params = {\n",
    "        \"get\": var,\n",
    "        \"for\": \"tract:*\",\n",
    "        \"in\": [\n",
    "            f\"county:{counties}\",\n",
    "            f\"state:{state}\",\n",
    "        ],\n",
    "        \"key\": census_api_key,\n",
    "    }\n",
    "    rq = requests.get(base_url, params=query_params)\n",
    "    data = rq.json()\n",
    "    acs_df = pd.DataFrame(data[1:], columns=data[0])\n",
    "    # Cast numeric columns to numeric types\n",
    "    cols = acs_df.columns.to_list()\n",
    "\n",
    "    if table_id:\n",
    "        str_cols = [\"GEO_ID\", \"NAME\", \"state\", \"county\", \"tract\"]\n",
    "    else:\n",
    "        str_cols = [\"state\", \"county\", \"tract\"]\n",
    "    num_cols = list(set(cols) - set(str_cols))\n",
    "    acs_df[num_cols] = acs_df[num_cols].apply(pd.to_numeric)\n",
    "\n",
    "    # Drop annotation columns\n",
    "    if drop_anno_cols:\n",
    "        acs_df = acs_df.loc[\n",
    "            :, ~((acs_df.columns.str.endswith(\"EA\")) | (acs_df.columns.str.endswith(\"MA\")))\n",
    "        ].copy()\n",
    "\n",
    "    if drop_margin_cols:\n",
    "        acs_df = acs_df.loc[:, ~acs_df.columns.str.endswith(\"M\").copy()]\n",
    "\n",
    "    # add tract id column\n",
    "    acs_df[\"tract_geoid\"] = acs_df[\"state\"] + acs_df[\"county\"] + acs_df[\"tract\"]\n",
    "\n",
    "    # rename columns\n",
    "    acs_df = acs_df.rename(columns={\"county\": \"fipco\"})\n",
    "\n",
    "    # drop redundent columns\n",
    "    if table_id:\n",
    "        acs_df = acs_df.drop(columns=[\"GEO_ID\", \"NAME\", \"state\", \"tract\"])\n",
    "    else:\n",
    "        acs_df = acs_df.drop(columns=[\"state\", \"tract\"])\n",
    "\n",
    "    return acs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pull_census_tracts_geodata(year=2020, cartographic=False):\n",
    "    \"\"\"\n",
    "    Pulls Census Tracts from TIGERweb REST API and returns Geopandas GeoDataframe.\n",
    "    Default year is 2020 which is the latest-available vintage for TIGER tracts.\n",
    "\n",
    "    How to choose vintage: https://www2.census.gov/geo/pdfs/maps-data/data/tiger/How_do_I_choose_TIGER_vintage.pdf\n",
    "\n",
    "    Parameters\n",
    "    -------------------\n",
    "    year (int):\n",
    "    the TIGER vintage.\n",
    "    list of valid years: [2012,2015,2016,2017,2018,2019,2020]\n",
    "\n",
    "    catrographic (bool):\n",
    "    If the cartographic parameter is set to true, a generalized version of tracts is returned\n",
    "    with water areas clipped.\n",
    "\n",
    "    Author: Joshua Croff\n",
    "    Source: https://tigerweb.geo.census.gov/tigerwebmain/TIGERweb_restmapservice.html\n",
    "    \"\"\"\n",
    "    import geopandas as gpd\n",
    "    import requests\n",
    "\n",
    "    valid_years = [2012, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022]\n",
    "    pre_2020 = [2012, 2015, 2016, 2017, 2018, 2019]\n",
    "    if year not in valid_years:\n",
    "        print(\"Error- vintage not available. Please see docstring for valid years\")\n",
    "        return\n",
    "\n",
    "    if year == 2020 and cartographic == True:\n",
    "        map_service = f\"Generalized_TAB{year}\"\n",
    "    elif year == 2020:\n",
    "        map_service = f\"tigerWMS_Census{year}\"\n",
    "        layer_id = \"6\"\n",
    "    elif year in pre_2020 and cartographic == True:\n",
    "        map_service = f\"Generalized_ACS{year}\"\n",
    "    elif year in pre_2020:\n",
    "        map_service = f\"tigerWMS_ACS{year}\"\n",
    "        layer_id = \"8\"\n",
    "    elif year > 2020 and cartographic == True:\n",
    "        map_service = f\"Generalized_ACS{year}\"\n",
    "    else:\n",
    "        map_service = f\"tigerWMS_ACS{year}\"\n",
    "        layer_id = \"6\"\n",
    "\n",
    "    state = \"06\"\n",
    "    counties = \"('001','013','041','055','075','081','085','095','097')\"\n",
    "    where_str = f\"where=STATE='{state}'+AND+COUNTY+IN{counties}\"\n",
    "    query_args = [where_str, \"outFields=GEOID&f=geojson\"]\n",
    "\n",
    "    if cartographic:\n",
    "        url = \"/\".join(\n",
    "            [\n",
    "                \"https://tigerweb.geo.census.gov\",\n",
    "                \"arcgis\",\n",
    "                \"rest\",\n",
    "                \"services\",\n",
    "                map_service,\n",
    "                \"Tracts_Blocks\",\n",
    "                \"MapServer\",\n",
    "                \"3\",\n",
    "                \"query?{}\".format(\"&\".join(query_args)),\n",
    "            ]\n",
    "        )\n",
    "    else:\n",
    "        url = \"/\".join(\n",
    "            [\n",
    "                \"https://tigerweb.geo.census.gov\",\n",
    "                \"arcgis\",\n",
    "                \"rest\",\n",
    "                \"services\",\n",
    "                \"TIGERweb\",\n",
    "                map_service,\n",
    "                \"MapServer\",\n",
    "                layer_id,\n",
    "                \"query?{}\".format(\"&\".join(query_args)),\n",
    "            ]\n",
    "        )\n",
    "    r = requests.get(url)\n",
    "    geog_json = r.json()\n",
    "    geog_gdf = gpd.GeoDataFrame.from_features(geog_json[\"features\"], crs=\"EPSG:4326\")\n",
    "\n",
    "    # rename GEOID column to tract_geoid\n",
    "    geog_gdf = geog_gdf.rename(columns={\"GEOID\": \"tract_geoid\"})\n",
    "    return geog_gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read selected ACS varibles from csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "acs_epc_selected_vars = pd.read_csv(\"Data/acs_table_variables_epc_factors.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "acs_vars_lst = acs_epc_selected_vars[\"ACS_Table_Variable\"].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query ACS API\n",
    "#### [Census American Community Survey 5-Year Data API Documentation](https://www.census.gov/data/developers/data-sets/acs-5year.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull american community survey tabular data\n",
    "acs_df = pull_acs_5_year_est_data(\n",
    "    census_api_key=api_key, acs_year=2022, tbl_prof_type=\"Detailed\", select_table_vars=acs_vars_lst\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull american community survey geographic data\n",
    "acs_gdf = pull_census_tracts_geodata(year=2022, cartographic=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rename columns for consistancy with prior epcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = {\n",
    "    \"fipco\": \"county_fip\",\n",
    "    \"B03002_001E\": \"tot_pop_poc\",\n",
    "    \"B01001_001E\": \"tot_pop_se\",\n",
    "    \"C17002_001E\": \"tot_pop_po\",\n",
    "    \"C18108_001E\": \"tot_pop_ci\",\n",
    "    \"B08201_001E\": \"tot_hh\",\n",
    "    \"B11004_001E\": \"tot_fam\",\n",
    "    \"B16005_001E\": \"tot_pop_ov\",\n",
    "    \"B25070_010E\": \"pop_hus_re\",\n",
    "    \"B08201_002E\": \"pop_zvhhs\",\n",
    "}\n",
    "acs_df.rename(columns=cols, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate epc and populations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate poc population (total population - not hispanic or latino white alone)\n",
    "acs_df[\"pop_poc\"] = acs_df[\"tot_pop_poc\"] - acs_df[\"B03002_003E\"]\n",
    "\n",
    "# calculate senior population\n",
    "acs_df[\"pop_over75\"] = (\n",
    "    acs_df[\"B01001_023E\"]\n",
    "    + acs_df[\"B01001_024E\"]\n",
    "    + acs_df[\"B01001_025E\"]\n",
    "    + acs_df[\"B01001_047E\"]\n",
    "    + acs_df[\"B01001_048E\"]\n",
    "    + acs_df[\"B01001_049E\"]\n",
    ")\n",
    "\n",
    "# calculate single parent family population (male householder, no spouse present + female householder, no spouse present)\n",
    "acs_df[\"pop_spfam\"] = acs_df[\"B11004_010E\"] + acs_df[\"B11004_016E\"]\n",
    "\n",
    "# calculate limited english proficiency population (primarily speaks a language other than English at home and speaks English less than \"very well\" or \"not at all\")\n",
    "acs_df[\"pop_lep\"] = (\n",
    "    acs_df[\"B16005_007E\"]\n",
    "    + acs_df[\"B16005_008E\"]\n",
    "    + acs_df[\"B16005_012E\"]\n",
    "    + acs_df[\"B16005_013E\"]\n",
    "    + acs_df[\"B16005_017E\"]\n",
    "    + acs_df[\"B16005_018E\"]\n",
    "    + acs_df[\"B16005_022E\"]\n",
    "    + acs_df[\"B16005_023E\"]\n",
    "    + acs_df[\"B16005_029E\"]\n",
    "    + acs_df[\"B16005_030E\"]\n",
    "    + acs_df[\"B16005_034E\"]\n",
    "    + acs_df[\"B16005_035E\"]\n",
    "    + acs_df[\"B16005_039E\"]\n",
    "    + acs_df[\"B16005_040E\"]\n",
    "    + acs_df[\"B16005_044E\"]\n",
    "    + acs_df[\"B16005_045E\"]\n",
    ")\n",
    "\n",
    "# calculate population below 200% of poverty (total population - population above 200% of poverty)\n",
    "acs_df[\"pop_below2\"] = acs_df[\"tot_pop_po\"] - acs_df[\"C17002_008E\"]\n",
    "\n",
    "# calculate population with a disability (total civilian non-institutionalized population - population with no disability)\n",
    "acs_df[\"pop_disabi\"] = acs_df[\"tot_pop_ci\"] - (\n",
    "    acs_df[\"C18108_005E\"] + acs_df[\"C18108_009E\"] + acs_df[\"C18108_013E\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate epc shares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "acs_df[\"pct_poc\"] = np.where(\n",
    "    acs_df[\"tot_pop_poc\"] == 0, 0, (acs_df[\"pop_poc\"] / acs_df[\"tot_pop_poc\"])\n",
    ")\n",
    "acs_df[\"pct_over75\"] = np.where(\n",
    "    acs_df[\"tot_pop_se\"] == 0, 0, (acs_df[\"pop_over75\"] / acs_df[\"tot_pop_se\"])\n",
    ")\n",
    "acs_df[\"pct_spfam\"] = np.where(acs_df[\"tot_fam\"] == 0, 0, (acs_df[\"pop_spfam\"] / acs_df[\"tot_fam\"]))\n",
    "acs_df[\"pct_lep\"] = np.where(\n",
    "    acs_df[\"tot_pop_ov\"] == 0, 0, (acs_df[\"pop_lep\"] / acs_df[\"tot_pop_ov\"])\n",
    ")\n",
    "acs_df[\"pct_below2\"] = np.where(\n",
    "    acs_df[\"tot_pop_po\"] == 0, 0, (acs_df[\"pop_below2\"] / acs_df[\"tot_pop_po\"])\n",
    ")\n",
    "acs_df[\"pct_disab\"] = np.where(\n",
    "    acs_df[\"tot_pop_ci\"] == 0, 0, (acs_df[\"pop_disabi\"] / acs_df[\"tot_pop_ci\"])\n",
    ")\n",
    "acs_df[\"pct_zvhhs\"] = np.where(acs_df[\"tot_hh\"] == 0, 0, (acs_df[\"pop_zvhhs\"] / acs_df[\"tot_hh\"]))\n",
    "acs_df[\"pct_hus_re\"] = np.where(acs_df[\"tot_hh\"] == 0, 0, (acs_df[\"pop_hus_re\"] / acs_df[\"tot_hh\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flag epcs and epc levels (high, higher, highest) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flag halfsd columns and count factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_dict_halfsd = {\n",
    "    \"pct_over75\": \"over75_1_2\",\n",
    "    \"pct_poc\": \"poc_1_2\",\n",
    "    \"pct_spfam\": \"spfam_1_2\",\n",
    "    \"pct_disab\": \"disab_1_2\",\n",
    "    \"pct_lep\": \"lep_1_2\",\n",
    "    \"pct_below2\": \"below2_1_2\",\n",
    "    \"pct_zvhhs\": \"zvhh_1_2\",\n",
    "    \"pct_hus_re\": \"hus_re_1_2\",\n",
    "}\n",
    "\n",
    "flag_mult_columns(acs_df, cols_dict_halfsd, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "halfsd_cols_list = [\n",
    "    \"below2_1_2\",\n",
    "    \"poc_1_2\",\n",
    "    \"spfam_1_2\",\n",
    "    \"disab_1_2\",\n",
    "    \"lep_1_2\",\n",
    "    \"over75_1_2\",\n",
    "    \"zvhh_1_2\",\n",
    "    \"hus_re_1_2\",\n",
    "]\n",
    "acs_df[\"count_1_2\"] = acs_df[halfsd_cols_list].sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flag halfsd epc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "halfsd_remain = [\"spfam_1_2\", \"disab_1_2\", \"lep_1_2\", \"over75_1_2\", \"zvhh_1_2\", \"hus_re_1_2\"]\n",
    "halfsd_cond = ((acs_df[\"poc_1_2\"] == 1) & (acs_df[\"below2_1_2\"] == 1)) | (\n",
    "    (acs_df[\"below2_1_2\"] == 1) & (acs_df[halfsd_remain].sum(axis=1) >= 3)\n",
    ")\n",
    "acs_df[\"epc50p_1_2\"] = np.where(halfsd_cond, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flag onesd columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_dict_onesd = {\n",
    "    \"pct_over75\": \"over75_1\",\n",
    "    \"pct_poc\": \"poc_1\",\n",
    "    \"pct_spfam\": \"spfam_1\",\n",
    "    \"pct_disab\": \"disab_1\",\n",
    "    \"pct_lep\": \"lep_1\",\n",
    "    \"pct_below2\": \"below2_1\",\n",
    "    \"pct_zvhhs\": \"zvhh_1\",\n",
    "    \"pct_hus_re\": \"hus_re_1\",\n",
    "}\n",
    "\n",
    "flag_mult_columns(acs_df, cols_dict_onesd, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "onesd_cols_list = [\n",
    "    \"below2_1\",\n",
    "    \"poc_1\",\n",
    "    \"spfam_1\",\n",
    "    \"disab_1\",\n",
    "    \"lep_1\",\n",
    "    \"over75_1\",\n",
    "    \"zvhh_1\",\n",
    "    \"hus_re_1\",\n",
    "]\n",
    "acs_df[\"count_1\"] = acs_df[onesd_cols_list].sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flag onesd epc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "onesd_remain = [\"spfam_1\", \"disab_1\", \"lep_1\", \"over75_1\", \"zvhh_1\", \"hus_re_1\"]\n",
    "onesd_cond = ((acs_df[\"poc_1\"] == 1) & (acs_df[\"below2_1\"] == 1)) | (\n",
    "    (acs_df[\"below2_1\"] == 1) & (acs_df[onesd_remain].sum(axis=1) >= 3)\n",
    ")\n",
    "acs_df[\"epc50p_1\"] = np.where(onesd_cond, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flag onehalfsd columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_dict_onehalfsd = {\n",
    "    \"pct_over75\": \"over75_1ha\",\n",
    "    \"pct_poc\": \"poc_1ha\",\n",
    "    \"pct_spfam\": \"spfam_1ha\",\n",
    "    \"pct_disab\": \"disab_1ha\",\n",
    "    \"pct_lep\": \"lep_1ha\",\n",
    "    \"pct_below2\": \"below2_1ha\",\n",
    "    \"pct_zvhhs\": \"zvhh_1ha\",\n",
    "    \"pct_hus_re\": \"hus_re_1ha\",\n",
    "}\n",
    "\n",
    "flag_mult_columns(acs_df, cols_dict_onehalfsd, 1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehalfsd_cols_list = [\n",
    "    \"below2_1ha\",\n",
    "    \"poc_1ha\",\n",
    "    \"spfam_1ha\",\n",
    "    \"disab_1ha\",\n",
    "    \"lep_1ha\",\n",
    "    \"over75_1ha\",\n",
    "    \"zvhh_1ha\",\n",
    "    \"hus_re_1ha\",\n",
    "]\n",
    "acs_df[\"count_1ha\"] = acs_df[onehalfsd_cols_list].sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flag onehalfsd epc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehalfsd_remain = [\"spfam_1ha\", \"disab_1ha\", \"lep_1ha\", \"over75_1ha\", \"zvhh_1ha\", \"hus_re_1ha\"]\n",
    "onehalfsd_cond = ((acs_df[\"poc_1ha\"] == 1) & (acs_df[\"below2_1ha\"] == 1)) | (\n",
    "    (acs_df[\"below2_1ha\"] == 1) & (acs_df[onehalfsd_remain].sum(axis=1) >= 3)\n",
    ")\n",
    "acs_df[\"epc50p_1ha\"] = np.where(onehalfsd_cond, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flag 2050 epcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "acs_df[\"epc_2050p\"] = np.where(\n",
    "    (acs_df[\"epc50p_1ha\"] == 1) | (acs_df[\"epc50p_1\"] == 1) | (acs_df[\"epc50p_1_2\"]), 1, 0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create epc classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "acs_df[\"epc_class\"] = acs_df.apply(set_epc_class, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "epc_class\n",
       "High       174\n",
       "Higher     131\n",
       "Highest     48\n",
       "NA           0\n",
       "Name: epc_2050p, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acs_df.groupby(\"epc_class\")[\"epc_2050p\"].agg(\"sum\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate regional statistics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "epc_region_stats = (\n",
    "    acs_df.agg(\n",
    "        {\n",
    "            \"pct_over75\": [\"mean\", \"std\"],\n",
    "            \"pct_poc\": [\"mean\", \"std\"],\n",
    "            \"pct_lep\": [\"mean\", \"std\"],\n",
    "            \"pct_spfam\": [\"mean\", \"std\"],\n",
    "            \"pct_below2\": [\"mean\", \"std\"],\n",
    "            \"pct_disab\": [\"mean\", \"std\"],\n",
    "            \"pct_zvhhs\": [\"mean\", \"std\"],\n",
    "            \"pct_hus_re\": [\"mean\", \"std\"],\n",
    "        }\n",
    "    )\n",
    "    .transpose()\n",
    "    .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "epc_region_stats.rename(columns={\"index\": \"factors\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "epc_factors = {\n",
    "    \"pct_over75\": \"Seniors 75 Years and Over\",\n",
    "    \"pct_poc\": \"People of Color\",\n",
    "    \"pct_lep\": \"Limited English Proficiency\",\n",
    "    \"pct_spfam\": \"Single Parent Families\",\n",
    "    \"pct_below2\": \"Low-Income (<200% Federal Poverty Level-FPL)\",\n",
    "    \"pct_disab\": \"People with Disability\",\n",
    "    \"pct_zvhhs\": \"Zero-Vehicle Household\",\n",
    "    \"pct_hus_re\": \"Rent-Burdened\",\n",
    "}\n",
    "epc_region_stats[\"factors\"] = epc_region_stats[\"factors\"].replace(epc_factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "epc_region_stats[\"mean\"] = epc_region_stats[\"mean\"].round(decimals=2)\n",
    "epc_region_stats[\"std\"] = epc_region_stats[\"std\"].round(decimals=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create fields for .5, 1, and 1.5 sd from mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "epc_region_stats[\"plus_half_sd\"] = (\n",
    "    epc_region_stats[\"mean\"] + (0.5 * epc_region_stats[\"std\"])\n",
    ").round(decimals=2)\n",
    "\n",
    "epc_region_stats[\"plus_one_sd\"] = (epc_region_stats[\"mean\"] + epc_region_stats[\"std\"]).round(\n",
    "    decimals=2\n",
    ")\n",
    "\n",
    "epc_region_stats[\"plus_one_half_sd\"] = (\n",
    "    epc_region_stats[\"mean\"] + (1.5 * epc_region_stats[\"std\"])\n",
    ").round(decimals=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>factors</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>plus_half_sd</th>\n",
       "      <th>plus_one_sd</th>\n",
       "      <th>plus_one_half_sd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Seniors 75 Years and Over</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>People of Color</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Limited English Proficiency</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Single Parent Families</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Low-Income (&lt;200% Federal Poverty Level-FPL)</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>People with Disability</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Zero-Vehicle Household</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Rent-Burdened</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        factors  mean   std  plus_half_sd  \\\n",
       "0                     Seniors 75 Years and Over  0.07  0.06          0.10   \n",
       "1                               People of Color  0.61  0.23          0.72   \n",
       "2                   Limited English Proficiency  0.07  0.08          0.11   \n",
       "3                        Single Parent Families  0.12  0.09          0.16   \n",
       "4  Low-Income (<200% Federal Poverty Level-FPL)  0.18  0.13          0.24   \n",
       "5                        People with Disability  0.10  0.05          0.12   \n",
       "6                        Zero-Vehicle Household  0.10  0.13          0.16   \n",
       "7                                 Rent-Burdened  0.10  0.08          0.14   \n",
       "\n",
       "   plus_one_sd  plus_one_half_sd  \n",
       "0         0.13              0.16  \n",
       "1         0.84              0.96  \n",
       "2         0.15              0.19  \n",
       "3         0.21              0.26  \n",
       "4         0.31              0.38  \n",
       "5         0.15              0.18  \n",
       "6         0.23              0.30  \n",
       "7         0.18              0.22  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epc_region_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "epc_region_stats.to_csv(\"Data/epc_regional_stats_ACS2022.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join census tracts geo to epc df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "acs_df.rename(columns={\"tract_geoid20\": \"tract_geoid\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "epc_gdf = pd.merge(acs_gdf, acs_df, on=\"tract_geoid\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_cols = [\n",
    "    \"tract_geoid\",\n",
    "    \"county_fip\",\n",
    "    \"tot_pop_poc\",\n",
    "    \"tot_pop_se\",\n",
    "    \"tot_pop_po\",\n",
    "    \"tot_pop_ci\",\n",
    "    \"tot_pop_ov\",\n",
    "    \"tot_hh\",\n",
    "    \"tot_fam\",\n",
    "    \"pop_poc\",\n",
    "    \"pop_over75\",\n",
    "    \"pop_spfam\",\n",
    "    \"pop_lep\",\n",
    "    \"pop_below2\",\n",
    "    \"pop_disabi\",\n",
    "    \"pop_hus_re\",\n",
    "    \"pop_zvhhs\",\n",
    "    \"pct_poc\",\n",
    "    \"pct_over75\",\n",
    "    \"pct_spfam\",\n",
    "    \"pct_lep\",\n",
    "    \"pct_below2\",\n",
    "    \"pct_disab\",\n",
    "    \"pct_hus_re\",\n",
    "    \"pct_zvhhs\",\n",
    "    \"poc_1_2\",\n",
    "    \"over75_1_2\",\n",
    "    \"spfam_1_2\",\n",
    "    \"lep_1_2\",\n",
    "    \"disab_1_2\",\n",
    "    \"below2_1_2\",\n",
    "    \"hus_re_1_2\",\n",
    "    \"zvhh_1_2\",\n",
    "    \"epc_2050p\",\n",
    "    \"epc_class\",\n",
    "    # \"epc_2050\",\n",
    "    # \"c2050_2050p\",\n",
    "    \"geometry\",\n",
    "]\n",
    "epc_path = \"Data/epc_acs2022.geojson\"\n",
    "epc_gdf[final_cols].to_file(epc_path, driver=\"GeoJSON\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output tabular data\n",
    "final_cols.remove(\"geometry\")\n",
    "acs_df[final_cols].to_csv(\"Data/epc_acs2022.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Publish to redshift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Info: Set AWS creds using 'default' creds.\n",
      "dataframe on S3 at mtc-redshift-upload:components/equity_priority_communities_acs2018_2022.csv\n",
      "DROP TABLE IF EXISTS basis.equity_priority_communities_acs2018_2022\n",
      "\n",
      "\n",
      "CREATE TABLE basis.equity_priority_communities_acs2018_2022(\n",
      "tract_geoid varchar(22),\n",
      "county_fip varchar(6),\n",
      "tot_pop_poc float,\n",
      "tot_pop_se float,\n",
      "tot_pop_po float,\n",
      "tot_pop_ci float,\n",
      "tot_pop_ov float,\n",
      "tot_hh float,\n",
      "tot_fam float,\n",
      "pop_poc float,\n",
      "pop_over75 float,\n",
      "pop_spfam float,\n",
      "pop_lep float,\n",
      "pop_below2 float,\n",
      "pop_disabi float,\n",
      "pop_hus_re float,\n",
      "pop_zvhhs float,\n",
      "pct_poc float,\n",
      "pct_over75 float,\n",
      "pct_spfam float,\n",
      "pct_lep float,\n",
      "pct_below2 float,\n",
      "pct_disab float,\n",
      "pct_hus_re float,\n",
      "pct_zvhhs float,\n",
      "poc_1_2 float,\n",
      "over75_1_2 float,\n",
      "spfam_1_2 float,\n",
      "lep_1_2 float,\n",
      "disab_1_2 float,\n",
      "below2_1_2 float,\n",
      "hus_re_1_2 float,\n",
      "zvhh_1_2 float,\n",
      "epc_2050p float,\n",
      "epc_class varchar(14));\n",
      "\n",
      "\n",
      "COPY basis.equity_priority_communities_acs2018_2022\n",
      "                FROM 's3://mtc-redshift-upload/components/equity_priority_communities_acs2018_2022.csv'\n",
      "                CREDENTIALS 'aws_access_key_id=XXX;aws_secret_access_key=XXX'\n",
      "                EMPTYASNULL\n",
      "                FILLRECORD\n",
      "                TIMEFORMAT as auto\n",
      "                DATEFORMAT as auto\n",
      "                NULL AS nan\n",
      "                CSV\n",
      "                IGNOREHEADER 1;\n",
      "\n",
      "\n",
      "table created on Redshift: basis.equity_priority_communities_acs2018_2022\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'CREATE TABLE basis.equity_priority_communities_acs2018_2022(\\ntract_geoid varchar(22),\\ncounty_fip varchar(6),\\ntot_pop_poc float,\\ntot_pop_se float,\\ntot_pop_po float,\\ntot_pop_ci float,\\ntot_pop_ov float,\\ntot_hh float,\\ntot_fam float,\\npop_poc float,\\npop_over75 float,\\npop_spfam float,\\npop_lep float,\\npop_below2 float,\\npop_disabi float,\\npop_hus_re float,\\npop_zvhhs float,\\npct_poc float,\\npct_over75 float,\\npct_spfam float,\\npct_lep float,\\npct_below2 float,\\npct_disab float,\\npct_hus_re float,\\npct_zvhhs float,\\npoc_1_2 float,\\nover75_1_2 float,\\nspfam_1_2 float,\\nlep_1_2 float,\\ndisab_1_2 float,\\nbelow2_1_2 float,\\nhus_re_1_2 float,\\nzvhh_1_2 float,\\nepc_2050p float,\\nepc_class varchar(14));'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Push to S3\n",
    "data_name = \"equity_priority_communities_acs2018_2022\"\n",
    "bucket = \"mtc-redshift-upload\"\n",
    "df = acs_df[final_cols]\n",
    "schema = \"basis\"\n",
    "\n",
    "key = f\"components/{data_name}.csv\"\n",
    "post_df_to_s3(df, bucket, key)\n",
    "\n",
    " ## Push to Redshift\n",
    "ctypes = create_column_type_dict(df)\n",
    "tablename = f\"{schema}.{data_name}\"\n",
    "s3_path = f\"s3://{bucket}/{key}\"\n",
    "create_redshift_table_via_s3(tablename, s3_path, ctypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Publish to arcgis online"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "publish_geojson_to_agol(\n",
    "    geojson_path=epc_path,\n",
    "    layer_name=\"DRAFT Equity Priority Communities - Plan Bay Area 2050 Plus (ACS 2022)\",\n",
    "    layer_snippet=\"\"\"This dataset represents tract information related to Equity Priority Communities \n",
    "    for Plan Bay Area 2050 Plus. The dataset was developed using American Community Survey 2018-2022 data for eight variables considered.\"\"\",\n",
    "    tags=\"bay area, equity, policy, planning, environmental justice, acs, american community survey, epc, community of concern\",\n",
    "    client=gis,\n",
    "    folder=\"plan_policy\",\n",
    "    overwrite=True,\n",
    "    f_layer_id=\"15a30787f659423ea3d40c07c5b2a31a\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Field Map Dictionary to Rename Feature Class Alias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# field_metadata = pd.read_csv(\"Data/EPC_Schema_pba2050p.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# field_metadata.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict(zip(field_metadata[\"Field Name\"], field_metadata[\"Alias\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
